# -*- coding: utf-8 -*-
"""ModelTesting

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TGf9s5CmvPCFcL1LlHpZJnFE5sLgdm1W
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import boxcox
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from scipy.special import inv_boxcox
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings("ignore")

## read the datset from your local drive
from google.colab import files
upload = files.upload()

## Upload the cleaned dataset
## upload the dataset
import pandas as pd
X_train = pd.read_csv('Covid_X_train_sc.csv')
X_test = pd.read_csv('Covid_X_test_sc.csv')
y_train = pd.read_csv('Covid_y_train.csv')
y_test = pd.read_csv('Covid_y_test.csv')



## Fit a Lasso Regression
from sklearn.linear_model import Ridge, Lasso
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)

y_train_pred = lasso.predict(X_train)
y_test_pred =  lasso.predict(X_test)

### Model evaluation
print('R2 score (train) : ',round(r2_score(y_train,y_train_pred),4))
print('R2 score (test) : ',round(r2_score(y_test,y_test_pred),4))
print('RMSE (train) : ', round(np.sqrt(mean_squared_error(y_train, y_train_pred)),4))
print('RMSE (test) : ', round(np.sqrt(mean_squared_error(y_test, y_test_pred)),4))

### What is wrong with this piece of code?
print(y_train_pred)
print(y_train)
print(y_train_pred[:, 1])
print(y_train.iloc[:,1])

### ToDo###################################
### 3 points
### How to fix the Model evaluation part
### Model evaluation
### Fill out the code below
y_train = y_train.iloc[:, 1]
y_train_pred = y_train_pred[:, 1]
y_test = y_test.iloc[:, 1]
y_test_pred = y_test_pred[:, 1]
print(y_train_pred)
print(y_train)
print(y_test_pred)
print(y_test)
### Model evaluation
print('R2 score (train) : ',round(r2_score(y_train,y_train_pred),4))
print('R2 score (test) : ',round(r2_score(y_test,y_test_pred),4))
print('RMSE (train) : ', round(np.sqrt(mean_squared_error(y_train,
y_train_pred)),4))
print('RMSE (test) : ', round(np.sqrt(mean_squared_error(y_test, y_test_pred)),4))

### What if I would like to set alpha=0.00125?
##### ToDo##############################################################
#### 6 points
#### fill out the code below
### fit a new lasso model
### fit it with X_train and y_train
### make predictions for the training set and testing set
### Perform mdoel evaluation using both training lables and testing labels
### using both r2_score and rmse

from sklearn.linear_model import Ridge, Lasso
lasso = Lasso(alpha=0.00125)
lasso.fit(X_train, y_train)

y_train_pred = lasso.predict(X_train)
y_test_pred =  lasso.predict(X_test)

### Model evaluation
print('R2 score (train) : ', round(r2_score(y_train,y_train_pred),4))
print('R2 score (test) : ',round(r2_score(y_test,y_test_pred),4))
print('RMSE (train) : ', round(np.sqrt(mean_squared_error(y_train, y_train_pred)),4))
print('RMSE (test) : ', round(np.sqrt(mean_squared_error(y_test, y_test_pred)),4))

### What if I would like to set alpha=0.5?
##### ToDo##############################################################
#### 6 points
### fill out the code below
### fit a new lasso model
### fit it with X_train and y_train
### make predictions for the training set and testing set
### Perform mdoel evaluation using both training lables and testing labels
### using both r2_score and rmse

from sklearn.linear_model import Ridge, Lasso
lasso = Lasso(alpha=0.5)
lasso.fit(X_train, y_train)

y_train_pred = lasso.predict(X_train)
y_test_pred =  lasso.predict(X_test)

### Model evaluation
print('R2 score (train) : ', round(r2_score(y_train,y_train_pred),4))
print('R2 score (test) : ',round(r2_score(y_test,y_test_pred),4))
print('RMSE (train) : ', round(np.sqrt(mean_squared_error(y_train, y_train_pred)),4))
print('RMSE (test) : ', round(np.sqrt(mean_squared_error(y_test, y_test_pred)),4))

###################################################################
### ToDO ##########################################################
## 15 points
### Hold-out cross-validation
###################################################################
### If I want to check the effect of different values of the tuning parameter
### in the LASSO penalty on the prediction performance, write a function
### that takes a sequence of alpha values as input and returns the result of R2
### score and RMSE of y_train and y_test
import numpy as np

def ModelTrainAndEvaluaion(alphaValues, xtrain, xtest, ytrain, ytest):
    """
    Parameters:

    -alphaValues: a vector of different tuning parameter values
    -xtrain: the training dataset
    -xtest: the testing set
    -ytrain: target var for training set
    -ytest: target var for testing set

    Output:
    returns a dictionary that stores the r2, rmse of the training and
    testing set respectively. Choose a dictionary data structure to
    save the result
    """

    ##########Define Data Structures ##################
    #### Define data structures to store your results
    ## first, get the number of different values
    num = len(alphaValues)
    ## Define data structures
    r2train = np.zeros(num)
    r2test = np.zeros(num)
    rmsetrain = np.zeros(num)
    rmsetest = np.zeros(num)

    #### Model fitting and evaluation with diffferent tuning parameters
    for i in range(num):
      ## Model fitting
      lasso = Lasso(alpha=alphaValues[i])
      lasso.fit(X_train, y_train)

      y_train_pred = lasso.predict(X_train)
      y_test_pred =  lasso.predict(X_test)

      # Model Evaluation
      r2train[i]=round(r2_score(y_train,y_train_pred),4)
      r2test[i]=round(r2_score(y_test,y_test_pred),4)
      rmsetrain[i] = round(np.sqrt(mean_squared_error(y_train, y_train_pred)),4)
      rmsetest[i] = round(np.sqrt(mean_squared_error(y_test, y_test_pred)),4)

    result = dict()
    result['r2train'] =  r2train
    result['r2test'] = r2test
    result['rmsetrain'] = rmsetrain
    result['rmsetest'] = rmsetest
    return result


### Example usage of this function
alphaValues = [0.0001, 0.00025,  0.0005, 0.00065, 0.001, 0.00125, 0.0025,0.005, 0.01, 0.1, 1]
result = ModelTrainAndEvaluaion(alphaValues, X_train, X_test, y_train, y_test)
print(result['r2test'])
print(result['rmsetest'])

###### ToDO################################################
##### 3 points

### Model selection
### How to choose the best tunning parameter?
import numpy as np
rmseValues = result['rmsetest']
## find the minimum value of the rmse]

print(np.min(result['rmsetest']))


## find the index of the minimum rmse values

minInd = np.argmin(rmseValues,axis=0)


## using this index and find the corresponding alpha value


bestAlpha = alphaValues[minInd]
print(bestAlpha)

######################################################
  ### ToDO #############################################
  ### 10 points ########################################
  ### Write the previous computations into a function
  ######################################################
  ## Can you change this into a function
  ## with alphaValues and rmseValues as input parameters
  ## return the minimum rmse value,
  ##        the index of the minimum rmse value
  ##      the corresponding alpha value
import numpy as np
def tuningParamSelection(alphaValues, rmseValues):
        """
        Parameters:

        -rmseValues: a list or an numpy array of rmse valus
        -alphaValues: a vector of different tuning parameter values

        Output:
        returns a dictionary that stores index of the minimum
        rmse and the corresponding alpha value that has the min rmse
        save the result in a dictionary and return it


    """
        num = len(alphaValues)
        rmseValues = result['rmsetest']

        for i in range(num):

## find the minimum value of the rmse]

          rmsetest[i] = np.min(result['rmsetest'])

## find the index of the minimum rmse values

          minInd = np.argmin(rmseValues[i],axis=0)


## using this index and find the corresponding alpha value

        bestAlpha = alphaValues[minInd]
        result['rmsetest'] = rmsetest
        result = dict()
        return result

result = ModelTrainAndEvaluaion(alphaValues, X_train, X_test, y_train, y_test)
alphaValues = [0.0001, 0.00025,  0.0005, 0.00065, 0.001, 0.00125, 0.0025,0.005, 0.01, 0.1, 1]
print(result['rmsetest'])
print(minInd)



##############################################################
### Todo #####################################################
### 10 points
### K fold cross-validation
##############################################################
folds = KFold(n_splits = 5)
params = {'alpha': [0.0001, 0.00025,  0.0005, 0.00065, 0.001, 0.00125, 0.0025,0.005, 0.01, 0.1, 1]}

model = Lasso()
### GridSearch and Model training
model_cv = GridSearchCV(estimator = model,
                              param_grid = params,
                              scoring= 'r2',
                              cv = folds,
                              return_train_score=True,
                              verbose = 1)
### use model_cv to fit with X_train and y_train

model_cv.fit(X_train, y_train)


### get the best alpha

alpha = model_cv.best_params_["alpha"]


print("Optimum alpha for %s is %f" %(model, alpha))

### get the best estimator from model_cv and set it as final_model


### use final_model to fit with X_train and y_train

final_model = model_cv.best_estimator_
final_model.fit(X_train, y_train)
## Model Prediction using X_train and X_test respectively
y_test_pred = final_model.predict(X_test)
y_train_pred = final_model.predict(X_train)

# Model Evaluation
print('RMSE (train) : ', round(np.sqrt(mean_squared_error(y_train, y_train_pred)),4))
print('RMSE (test) : ', round(np.sqrt(mean_squared_error(y_test, y_test_pred)),4))


## save the cross validation results into a data frame
cvResults = pd.DataFrame(model_cv.cv_results_)
cvResults.head(5)

cvResults['param_alpha'] = cvResults['param_alpha'].astype('float32')
print(cvResults)

fig, axes = plt.subplots(1, 4, figsize=(15,3))

## Check if the distribution of the residual looks like a Normal distribution
## (bell shape)
fig.suptitle('Assumtions of Linear Regression')
sns.distplot(y_train-y_train_pred , ax = axes[0])
axes[0].set_title('Distribution of Residuals')

### Check the linearity assumption using the observed-vs-predicted values
sns.scatterplot( y_train_pred, y_train  , ax = axes[1])
axes[1].set_title('Plot of y vs y_predicted')

### Check equal variances
sns.scatterplot(X_train.index,y_train- y_train_pred,ax = axes[2])
axes[2].set_title('Homoscedasticity/ Variance')
plt.tight_layout()

### Check independence of errors
sns.scatterplot(y_train_pred,(y_train-y_train_pred),ax = axes[3])
axes[3].set_title('Independence of Errors')
plt.ylabel("Residuals")
plt.xlabel("Fitted SalesPrice")
plt.tight_layout()

# plotting
fig = plt.figure(figsize=(7,3))
## use plt.plot to draw cvResults['param_alpha'] as x axis
## and use cvResults['mean_train_score'] as y axis
plt.plot(cvResults['param_alpha'],  cvResults['mean_train_score'] )
## use plt.plot to draw cvResults['param_alpha'] as x axis
## and use cvResults['mean_test_score'] as y axis
plt.plot( cvResults['param_alpha'], cvResults['mean_test_score']  )
plt.xlabel('alpha')
plt.ylabel('r2')

plt.title("r2 and alpha")
plt.legend(['train score', 'test score'], loc='upper left')
plt.show()

###### Combine the K-fold cross validation and model diagnostics
###### into a function.
###### The input of the function should include 1. model
###### For example, model can be Lasso() or Ridge()
###### 2. params should be a dictionary of the candidate alpha values
###### 3. dataset, xtrain, xtest ytrain, ytest
###### scoring criterion should be r2
###### return the final model selected by cross validation that has
###### the largest r2 value

### ToDO ###############################################################
### 15 points
from sklearn.linear_model import Ridge, Lasso
def ModelTrainAndEvaluaion(model, params, xtrain, xtest, ytrain, ytest):

  folds = KFold(n_splits = 5)
  params = {'alpha': [0.0001, 0.00025,  0.0005, 0.00065, 0.001, 0.00125, 0.0025,0.005, 0.01, 0.1, 1]}

  model = Lasso()
  ### GridSearch and Model training
  model_cv = GridSearchCV(estimator = model,
                              param_grid = params,
                              scoring= 'r2',
                              cv = folds,
                              return_train_score=True,
                              verbose = 1)
  ### use model_cv to fit with X_train and y_train

  model_cv.fit(X_train, y_train)


  ### get the best alpha

  alpha = model_cv.best_params_["alpha"]


  print("Optimum alpha for %s is %f" %(model, alpha))

  ### use final_model to fit with X_train and y_train

  final_model = model_cv.best_estimator_
  final_model.fit(X_train, y_train)



  return final_model

####  example use of this function
# params = {'alpha': [0.0001, 0.00025,  0.0005, 0.00065, 0.001, 0.00125, 0.0025,0.005, 0.01, 0.1, 1]}
finalModel = ModelTrainAndEvaluaion(Lasso(), params=params,
                                    xtrain=X_train, xtest=X_test, ytrain=y_train, ytest=y_test)
print('R2 score (train) : ',max(r2_score(y_train,y_train_pred),4))
print('R2 score (test) : ',max(r2_score(y_test,y_test_pred),4))

#### Use the function ModelTrainAndEvaluaion to fit a ridge regression with the
### following parameters params
params = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0,
                        9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100,200]}

################################################################################
### ToDO
### 2 points
### fill out the code here
ridge = ModelTrainAndEvaluaion(alphaValues, X_train, X_test, y_train, y_test)