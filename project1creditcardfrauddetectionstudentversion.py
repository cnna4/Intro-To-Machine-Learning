# -*- coding: utf-8 -*-
"""Project1CreditCardFraudDetectionStudentVersion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11ogsrXM5HeSx2fF6pnlY_vgARwRacmkD

# Project 1: Credit Card Fraud Detection
The total score for this project is 25. It will contribute 20 out of 100 in our final score. I will determine the deadline for this project later depending on our progress.
"""

from google.colab import files
upload = files.upload()



# Commented out IPython magic to ensure Python compatibility.
#####################################################
# Import all the tools we need

# Regular EDA (exploratory data analysis) and plotting libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# we want our plots to appear inside the notebook
# %matplotlib inline

# Models from Scikit-Learn
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

# Model Evaluations
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score ,accuracy_score
from sklearn.metrics import plot_roc_curve
from sklearn.model_selection import KFold
#####################################################

#Importing data
df1 = pd.read_csv("creditcard.csv")
df1.head()
### ToDO:
## Remove the Time feature
## 2 points
df= df1.drop('Time', axis = 1)

#### Exploratory Data Analysis
### ToDO:
## 2 points
cases = len(df)
nonfraud_count = len(df[df.Class == 0])
fraud_count = len(df[df.Class == 1  ])
fraud_percentage = round(fraud_count/nonfraud_count*100, 2)

from termcolor import colored as cl # text customization
print(cl('CASE COUNT', attrs = ['bold']))
print(cl('--------------------------------------------', attrs = ['bold']))
print(cl('Total number of cases are {}'.format(cases), attrs = ['bold']))
print(cl('Number of Non-fraud cases are {}'.format(nonfraud_count), attrs = ['bold']))
print(cl('Number of Non-fraud cases are {}'.format(fraud_count), attrs = ['bold']))
print(cl('Percentage of fraud cases is {}'.format(fraud_percentage), attrs = ['bold']))
print(cl('--------------------------------------------', attrs = ['bold']))

###################################################
## Training and Testing Data Split
X = df.drop('Class', axis = 1).values
y = df['Class'].values

### ToDO:
## 2 points
## Use test_size as 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2 , random_state = 0)

## Model Fitting Process
# Fit a  Logistic Regression as baseline
# once fit the model, make predictions using
# testing dataset X_test
### ToDO:
## 3 points
lr = LogisticRegression()
lr.fit(X_train,y_train  )
lr_ypred = lr.predict(X_test)

## Model Fitting Process
# Fit a Decision Tree Model
# once fit the model, make predictions using
# testing dataset X_test
### ToDO:
## 3 points
## use criterion="gini"
tree_model = DecisionTreeClassifier(criterion="gini")
tree_model.fit(X_train, y_train)
tree_ypred = tree_model.predict(X_test)

## Fit a Random Forest and make predictions using X_test
### ToDO:
## 3 points
from sklearn.ensemble import RandomForestClassifier # Random forest tree algorithm
rf = RandomForestClassifier()
rf.fit(X_train,y_train)
rf_ypred = rf.predict(X_test)

### Model Evaluation Process
### Using Classification Report
from sklearn.metrics import classification_report
print(classification_report(y_test, tree_ypred))
## To learn about ROC and AUC, you can read
## the tutorial here:
## https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc

### Using Confusion Matrix
# helper function
## add true and predicted in the x and y axis
def plot_confusionmatrix(y_train_pred,y_train,dom, classes):
    print(f'{dom} Confusion matrix')
    cf = confusion_matrix(y_train,y_train_pred)
    sns.heatmap(cf,annot=True,yticklabels=classes
               ,xticklabels=classes,cmap='Blues', fmt='g')
    plt.ylabel("True label")
    plt.xlabel("Predicted label")
    plt.tight_layout()
    plt.show()

## Evaluate baseline Logistic Regression Model
classes =['Not Fraud', 'Fraud']
print(classification_report(y_test, lr_ypred))
plot_confusionmatrix(lr_ypred,y_test,dom='Test', classes=classes)
plot_roc_curve(lr, X_test, y_test)

### ToDO:
## 3 points
## Evaluate Decision Tree Model for classification
## using classification_report()
## using plot_confusionmatrix
## Using plot_roc_curve
print((classification_report(y_test,tree_ypred)))
plot_confusionmatrix(tree_ypred,y_test,dom='Test', classes= classes)
plot_roc_curve(tree_model,X_test,y_test)

### ToDO:
## 3 points
## Evaluate Random Forest Model for classification
## using classification_report()
## using plot_confusionmatrix
## Using plot_roc_curve
print((classification_report(y_test,rf_ypred)))
plot_confusionmatrix(rf_ypred,y_test,dom='Test', classes= classes)
plot_roc_curve(rf,X_test,y_test)

### Fine-Tune Random Forest
# Create a hyperparameter grid for RandomForestClassifier
rf_grid = {"n_estimators": np.arange(10, 1000, 50),
           "max_depth": [None, 3, 5, 10],
           "min_samples_split": np.arange(2, 20, 2),
           "min_samples_leaf": np.arange(1, 20, 2)}

class_weight=dict({0:1,1:100})

np.random.seed(42)

## ToDO:
## 4 points
# Setup random hyperparameter search for RandomForestClassifier
rs_rf = RandomizedSearchCV(RandomForestClassifier(class_weight= class_weight),
                           param_distributions= rf_grid,
                           cv=2,
                           n_iter=2,
                           verbose=True)

# Fit random hyperparameter search model for RandomForestClassifier()
rs_rf.fit()
# Evaluate the randomized search RandomForestClassifier model
rs_rf.score()
# Make predictions with tuned model
rs_rf_ypred = rs_rf.predict()

## Fit a Random Forest with SMOTE method to deal with
## imbalanced dataset
## SMOTE technique with random forest
from imblearn.combine import SMOTETomek
from collections import Counter
os=SMOTETomek(0.75)
X_train_ns,y_train_ns=os.fit_resample(X_train,y_train)
print("The number of classes before fit {}".format(Counter(y_train)))
print("The number of classes after fit {}".format(Counter(y_train_ns)))

classifier=RandomForestClassifier()
classifier.fit(X_train_ns,y_train_ns)

rfs_ypred=classifier.predict(X_test)
print(classification_report(y_test, rfs_ypred))
plot_confusionmatrix(rfs_ypred,y_test,dom='Test', classes=classes)
plot_roc_curve(classifier, X_test, y_test)